# -*- coding: utf-8 -*-
"""credit card prediction .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xTK1iyMxA5BAS82VS5qCHItK0hzpF75Z
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

credit_card_data = pd.read_csv('creditcard.csv')

credit_card_data.head()

credit_card_data.tail()

#dataset information
credit_card_data.info()

#checking the number of missing values

credit_card_data.isnull().sum()

credit_card_data.fillna(credit_card_data.mean(), inplace=True)

credit_card_data.isnull().sum()

# distribution of legit transaction & fraudulent transaction
credit_card_data['Class'].value_counts()

"""This Dataset is highly unbalanced

0 -> Normal Transaction

1 -> Fradulent Transaction
"""

#seperate ting data for analysis
legit = credit_card_data[credit_card_data.Class == 0]
fraud = credit_card_data[credit_card_data.Class == 1]

print(legit.shape)
print(fraud.shape)

#statstical measures of the data
legit.Amount.describe()

"""#compare the valus of both transactions
credit_card_data.groupby('Class').mean()
"""

credit_card_data.groupby('Class').mean()

"""Under-sampling

build a sample dataset containg similar distibuton of normal transaction and fradulant transaction


"""

legit_sample=legit.sample(n=250)

"""concatenating two data frames"""

new_dataset=pd.concat([legit_sample,fraud],axis=0)

new_dataset.head()

new_dataset.tail()

new_dataset['Class'].value_counts()

new_dataset.groupby('Class').mean()

"""split the data into features and targets"""

x=new_dataset.drop(columns='Class',axis=1)
y=new_dataset['Class']

print(x)

print(y)

"""split the data into traing and test data"""

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,stratify=y,random_state=3)

print(x.shape,x_train.shape,x_test.shape)

"""Model Traing"""

model = LogisticRegression()

#traing the Logistic Regression model with Traing data
model.fit(x_train,y_train)

"""Model evaluation"""

#accuracy on Training Data
x_train_prediction=model.predict(x_train)
data_accuracy=accuracy_score(x_train_prediction,y_train)

print('Accuracy on Training Data:',data_accuracy)

X_test_prediction=model.predict(x_test)
data_accuracy=accuracy_score(X_test_prediction,y_test)

print('Accuracy on Test Data:',data_accuracy)

